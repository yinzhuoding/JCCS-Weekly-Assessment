{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "import string "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_data = pd.read_excel('Master JCCS LC Mods.xlsx',sheetname = 'All Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Bayside_data= pd.read_excel('Master JCCS LC Mods.xlsx',sheetname = 'Bayside')\n",
    "#Lamesa_data= pd.read_excel('Master JCCS LC Mods.xlsx',sheetname = 'La Mesa')\n",
    "#Reflection_data= pd.read_excel('Master JCCS LC Mods.xlsx',sheetname = 'Reflections')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are totally 235 records in our data set\n"
     ]
    }
   ],
   "source": [
    "print(\"There are totally \" + str(full_data.shape[0]) + \" records in our data set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>School</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>Date</th>\n",
       "      <th>Listening</th>\n",
       "      <th>Playing</th>\n",
       "      <th>Singing</th>\n",
       "      <th>Sharing</th>\n",
       "      <th>Trying</th>\n",
       "      <th>Working</th>\n",
       "      <th>Surprise</th>\n",
       "      <th>Effort</th>\n",
       "      <th>Hopeful</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bayside</td>\n",
       "      <td>Evaline</td>\n",
       "      <td>Aeids</td>\n",
       "      <td>2016-12-08</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>I learned another cord</td>\n",
       "      <td>I sang</td>\n",
       "      <td>I sang with teacher</td>\n",
       "      <td>The cords</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bayside</td>\n",
       "      <td>Eveline</td>\n",
       "      <td>Aeids</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>I surprised myself by liking how I played the bas</td>\n",
       "      <td>Playing the bass for th first time</td>\n",
       "      <td>Trying a new instrument</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bayside</td>\n",
       "      <td>Mario</td>\n",
       "      <td>Aguirre</td>\n",
       "      <td>2016-12-15</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes, I didn't know guitar was fun and easy</td>\n",
       "      <td>I tried reading the notes</td>\n",
       "      <td>That I am learning a new instrument</td>\n",
       "      <td>Guitar class was nice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    School FirstName LastName        Date  Listening  Playing  Singing  \\\n",
       "0  Bayside   Evaline     Aeids 2016-12-08          5        5        5   \n",
       "1  Bayside   Eveline     Aeids 2017-01-05          4        5        0   \n",
       "2  Bayside     Mario   Aguirre 2016-12-15          4        4        0   \n",
       "\n",
       "   Sharing  Trying  Working  \\\n",
       "0        4       3        0   \n",
       "1        3       4        1   \n",
       "2        0       4        0   \n",
       "\n",
       "                                            Surprise  \\\n",
       "0                             I learned another cord   \n",
       "1  I surprised myself by liking how I played the bas   \n",
       "2         Yes, I didn't know guitar was fun and easy   \n",
       "\n",
       "                               Effort                              Hopeful  \\\n",
       "0                              I sang                  I sang with teacher   \n",
       "1  Playing the bass for th first time              Trying a new instrument   \n",
       "2           I tried reading the notes  That I am learning a new instrument   \n",
       "\n",
       "                 Support  \n",
       "0              The cords  \n",
       "1                     No  \n",
       "2  Guitar class was nice  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some blanks in student response, and I set them to 'N/A' in order to run the code successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data.loc[full_data['Surprise'].isnull(), 'Surprise'] = 'N/A'\n",
    "full_data.loc[full_data['Effort'].isnull(), 'Effort'] = 'N/A'\n",
    "full_data.loc[full_data['Hopeful'].isnull(), 'Hopeful'] = 'N/A'\n",
    "full_data.loc[full_data['Support'].isnull(), 'Support'] = 'N/A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyze text information seperately for four questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_surprise = full_data['Surprise']\n",
    "word_effort = full_data['Effort']\n",
    "word_hopeful = full_data['Hopeful']\n",
    "word_support = full_data['Support']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_surprise = word_surprise.apply(lambda x: x.replace(\"'\",\"\"))\n",
    "word_effort = word_effort.apply(lambda x: x.replace(\"'\",\"\"))\n",
    "word_hopeful = word_hopeful.apply(lambda x: x.replace(\"'\",\"\"))\n",
    "word_support = word_support.apply(lambda x: x.replace(\"'\",\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Q1--How did you suprise yourself today? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Manually calculate the word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopword = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "punctuation = set(string.punctuation)\n",
    "Unifreq = defaultdict(int)\n",
    "for line in word_surprise:\n",
    "    r = line.lower()\n",
    "    r = ''.join([c for c in r if not c in punctuation])\n",
    "    for word in r.split():\n",
    "        if not word in stopword:\n",
    "            Unifreq[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(35, 'guitar'),\n",
       " (32, 'played'),\n",
       " (29, 'playing'),\n",
       " (27, 'new'),\n",
       " (25, 'song'),\n",
       " (25, 'learned'),\n",
       " (23, 'play'),\n",
       " (21, 'didnt'),\n",
       " (12, 'learn'),\n",
       " (11, 'chords'),\n",
       " (9, 'something'),\n",
       " (9, 'learning'),\n",
       " (8, 'chord'),\n",
       " (7, 'yes'),\n",
       " (7, 'good')]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Unifreq = [(Unifreq[w], w) for w in Unifreq]\n",
    "Unifreq.sort()\n",
    "Unifreq.reverse()\n",
    "Unifreq[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MostFreqWord(ngram_range, word_key, limit):\n",
    "    cv = CountVectorizer(ngram_range = ngram_range, stop_words = 'english',token_pattern = '\\\\b\\\\w+\\\\b')\n",
    "    cv.fit(word_key)\n",
    "    countvect = cv.transform(word_key).toarray()\n",
    "    voc = cv.vocabulary_\n",
    "    count = countvect.sum(axis = 0)\n",
    "    freq = dict()\n",
    "    for word in voc:\n",
    "        freq[word] = count[voc[word]]    \n",
    "    freq = [(freq[w], w) for w in freq]\n",
    "    freq.sort()\n",
    "    freq.reverse()\n",
    "    print(\"The most \" + str(limit)+ \" frequent keywords and there corresponding frequencies are:\")\n",
    "    print(freq[:limit])\n",
    "    return(freq[:limit])\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most 15 frequent keywords and there corresponding frequencies are:\n",
      "[(35, 'guitar'), (32, 'played'), (29, 'playing'), (27, 'new'), (25, 'song'), (25, 'learned'), (23, 'play'), (21, 'didnt'), (12, 'learn'), (11, 'chords'), (10, 'did'), (9, 'learning'), (8, 'chord'), (7, 'yes'), (7, 'good')]\n"
     ]
    }
   ],
   "source": [
    "surprise_uni = MostFreqWord((1,1),word_surprise, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most 15 frequent keywords and there corresponding frequencies are:\n",
      "[(54, 'playing'), (26, 'play'), (25, 'guitar'), (22, 'song'), (21, 'learning'), (15, 'new'), (14, 'chords'), (10, 'g'), (9, 'chord'), (8, 'strings'), (8, 'played'), (7, 'notes'), (7, 'instrument'), (7, 'bass'), (6, 'trying')]\n"
     ]
    }
   ],
   "source": [
    "effort_uni = MostFreqWord((1,1),word_effort, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most 15 frequent keywords and there corresponding frequencies are:\n",
      "[(38, 'playing'), (32, 'song'), (30, 'guitar'), (24, 'play'), (22, 'played'), (13, 'music'), (12, 'learning'), (11, 'good'), (10, 'songs'), (10, 'new'), (10, 'learned'), (8, 'making'), (6, 'notes'), (6, 'n'), (6, 'did')]\n"
     ]
    }
   ],
   "source": [
    "hopeful_uni = MostFreqWord((1,1),word_hopeful, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most 15 frequent keywords and there corresponding frequencies are:\n",
      "[(16, 'learning'), (15, 'play'), (12, 'guitar'), (11, 'chords'), (9, 'song'), (9, 'nope'), (8, 'playing'), (8, 'notes'), (7, 'better'), (6, 'time'), (6, 'thanks'), (6, 'practice'), (5, 'want'), (5, 'thank'), (5, 'strings')]\n"
     ]
    }
   ],
   "source": [
    "support_uni = MostFreqWord((1,1),word_support, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most 15 frequent keywords and there corresponding frequencies are:\n",
      "[(12, 'playing guitar'), (10, 'play guitar'), (10, 'new song'), (7, 'learned new'), (6, 'learn new'), (5, 'played song'), (5, 'learning new'), (4, 'play new'), (4, 'learned play'), (4, 'g chord'), (4, 'electric guitar'), (3, 'played new'), (3, 'played electric'), (3, 'new chords'), (3, 'didnt surprise')]\n"
     ]
    }
   ],
   "source": [
    "surprise_bi = MostFreqWord((2,2),word_surprise, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most 15 frequent keywords and there corresponding frequencies are:\n",
      "[(10, 'playing guitar'), (7, 'learning new'), (6, 'play guitar'), (6, 'new song'), (4, 'playing song'), (4, 'playing new'), (4, 'playing instrument'), (4, 'new chords'), (3, 'singing class'), (3, 'playing g'), (3, 'played guitar'), (3, 'play song'), (3, 'play g'), (3, 'learned play'), (3, 'g string')]\n"
     ]
    }
   ],
   "source": [
    "effort_bi = MostFreqWord((2,2),word_effort, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most 15 frequent keywords and there corresponding frequencies are:\n",
      "[(9, 'playing guitar'), (8, 'play guitar'), (6, 'played song'), (4, 'did good'), (3, 'playing music'), (3, 'played guitar'), (3, 'making song'), (3, 'blues riff'), (2, 'wrote song'), (2, 'string c'), (2, 'song good'), (2, 'read notes'), (2, 'playing song'), (2, 'playing new'), (2, 'playing difficult')]\n"
     ]
    }
   ],
   "source": [
    "hopeful_bi = MostFreqWord((2,2),word_hopeful, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most 15 frequent keywords and there corresponding frequencies are:\n",
      "[(4, 'want learn'), (4, 'learning play'), (3, 'reading notes'), (3, 'playing guitar'), (3, 'play better'), (2, 'time practice'), (2, 'teach play'), (2, 'song time'), (2, 'practice good'), (2, 'play faster'), (2, 'need help'), (2, 'learning notes'), (2, 'learning new'), (2, 'learning chords'), (2, 'extra time')]\n"
     ]
    }
   ],
   "source": [
    "support_bi = MostFreqWord((2,2),word_support, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 15, 12, 11, 9, 9, 8, 8, 7, 6, 6, 6, 5, 5, 5]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a for (a,b) in support_uni]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "results['Surprise_unigram'] =  [b for (a,b) in surprise_uni]\n",
    "results['Surprise_unigram_freq'] =  [a for (a,b) in surprise_uni]\n",
    "results['Surprise_bigram'] =  [b for (a,b) in surprise_bi]\n",
    "results['Surprise_bigram_freq'] =  [a for (a,b) in surprise_bi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results.to_csv(\"Text_Analysis_Yinzhuo_Ding.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range = (1,1), stop_words = 'english',token_pattern = '\\\\b\\\\w+\\\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='\\\\b\\\\w+\\\\b', tokenizer=None,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(word_surprise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "countvect = cv.transform(word_surprise).toarray()\n",
    "voc = cv.vocabulary_\n",
    "count = countvect.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq = dict()\n",
    "for word in voc:\n",
    "    freq[word] = count[voc[word]]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(35, 'guitar'),\n",
       " (32, 'played'),\n",
       " (29, 'playing'),\n",
       " (27, 'new'),\n",
       " (25, 'song'),\n",
       " (25, 'learned'),\n",
       " (24, 't'),\n",
       " (23, 'play'),\n",
       " (21, 'didn'),\n",
       " (12, 'learn'),\n",
       " (11, 'chords'),\n",
       " (10, 'did'),\n",
       " (9, 'learning'),\n",
       " (8, 'chord'),\n",
       " (7, 'yes')]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = [(freq[w], w) for w in freq]\n",
    "freq.sort()\n",
    "freq.reverse()\n",
    "freq[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
